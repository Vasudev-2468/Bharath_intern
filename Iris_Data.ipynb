{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPX8BAhfXfLynaRWI+wilnp"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A5OFEy3x45A5","executionInfo":{"status":"ok","timestamp":1702113840893,"user_tz":-330,"elapsed":997,"user":{"displayName":"VASUDEVAN S","userId":"00376140912833995267"}},"outputId":"8cf825dc-2b61-46ea-8207-8250deede511"},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 1.0\n"]}],"source":["# Import necessary libraries\n","import numpy as np\n","from sklearn import datasets\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score\n","\n","# Load the Iris dataset\n","iris = datasets.load_iris()\n","X = iris.data\n","y = iris.target\n","\n","# Split the dataset into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Standardize features by removing the mean and scaling to unit variance\n","scaler = StandardScaler()\n","X_train = scaler.fit_transform(X_train)\n","X_test = scaler.transform(X_test)\n","\n","# Create a Random Forest Classifier\n","classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n","\n","# Train the model\n","classifier.fit(X_train, y_train)\n","\n","# Make predictions on the test set\n","y_pred = classifier.predict(X_test)\n","\n","# Evaluate the accuracy\n","accuracy = accuracy_score(y_test, y_pred)\n","print(f\"Accuracy: {accuracy}\")\n"]},{"cell_type":"code","source":[],"metadata":{"id":"RAWOUALQ48R2"},"execution_count":null,"outputs":[]}]}